<!doctype html>
<html lang="ko">
<head>
  <meta charset="utf-8">
  <title>Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning">
  <link rel="stylesheet" href="/tech-knowledge-log/style.css?v=10">
</head>
<body>
  <header>
    <div class="header-content">
      <a href="/tech-knowledge-log/index.html" class="site-title">Tech Knowledge Log</a>
      <nav>
        <a href="/tech-knowledge-log/archive.html">Archive</a>
      </nav>
    </div>
  </header>
  <main class="container">
    <article class="post-content">
      <h1>Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning</h1>
      <div class="topic-meta">
        <div><strong>저자 / Authors:</strong> Peng Xia, Kaide Zeng, Jiaqi Liu, Can Qin, Fang Wu, Yiyang Zhou, Caiming Xiong, Huaxiu Yao</div>
        <div><strong>발행일 / Published:</strong> 2025-11-23</div>
        <div><strong>Arxiv ID:</strong> 2511.16043</div>
        <div><strong>Affiliation:</strong> University of North Carolina at Chapel Hill</div>
      </div>
      <section class="topic-section">
        <h2>내용</h2>
        <p>기존 LLM 에이전트는 사람이 수집한 데이터에 의존해 확장성이 제한되고, 자체 진화 방법도 모델 능력과 단일 회차 상호작용에 묶여 복잡한 교과과정(도구 사용·동적 추론 등)을 만들기 어렵습니다. Agent0는 외부 데이터 없이도 다중 단계의 공동 진화(co-evolution)와 도구 통합을 통해 고성능 에이전트를 스스로 발전시키는 완전 자율 프레임워크입니다. 동일한 기반 LLM에서 출발한 두 에이전트—점점 더 어려운 최전선 과제를 제시하는 커리큘럼 에이전트와 이를 해결하기 위해 도구를 활용해 학습하는 실행 에이전트—가 상호 경쟁하면서 실행 능력의 향상이 다시 더 복잡한, 도구를 고려한 과제 생성을 촉진하는 자기강화 사이클을 만듭니다. 실험에서 Agent0는 Qwen3-8B-Base의 수학적 추론 능력을 18%, 일반 추론 능력을 24% 향상시켰으며(코드 공개됨), 복잡한 문제 해결 능력 개선을 보였습니다.</p>
      </section>
      <section class="topic-section">
        <h2>Content</h2>
        <p>Large Language Model (LLM) Agents, often trained with Reinforcement Learning (RL), are constrained by a dependency on human-curated data, limiting scalability and tethering AI to human knowledge. Existing self-evolution frameworks offer an alternative but are typically restricted by the model's inherent capabilities and single-round interactions, hindering the development of complex curricula involving tool use or dynamic reasoning. We introduce Agent0, a fully autonomous framework that evolves high-performing agents without external data through multi-step co-evolution and seamless tool integration. Agent0 establishes a symbiotic competition between two agents initialized from the same base LLM: a curriculum agent that proposes increasingly challenging frontier tasks, and an executor agent that learns to solve them. We integrate external tools to enhance the executor's problem-solving capacity; this improvement, in turn, pressures the curriculum agent to construct more complex, tool-aware tasks. Through this iterative process, Agent0 establishes a self-reinforcing cycle that continuously produces high-quality curricula. Empirically, Agent0 substantially boosts reasoning capabilities, improving the Qwen3-8B-Base model by 18% on mathematical reasoning and 24% on general reasoning benchmarks. Code is available at https://github.com/aiming-lab/Agent0.</p>
        
        <div class="arxiv-links">
          <a href="https://arxiv.org/abs/2511.16043" class="arxiv-link" target="_blank" rel="noopener">View on Arxiv</a>
          <a href="https://huggingface.co/papers/2511.16043" class="hf-link" target="_blank" rel="noopener">View on HF</a>
        </div>
      </section>
    </article>
  </main>
  <footer>
    <p>&copy; 2025 Tech Knowledge Log. All rights reserved.</p>
  </footer>
  <script src="/tech-knowledge-log/script.js?v=10"></script>
</body>
</html>